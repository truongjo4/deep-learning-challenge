{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LambdaCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE   \n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10  \\\n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS   \n",
       "0       Independent          C1000    ProductDev   Association       1  \\\n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dla-1-2/m21/lms/starter/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying preprocessing steps from previous notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unneeded name columns\n",
    "application_df = application_df.drop(columns=['EIN', 'NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning application type\n",
    "application_threshold = 500\n",
    "value_counts_app = application_df['APPLICATION_TYPE'].value_counts()\n",
    "application_types_to_replace = [app_type for app_type in value_counts_app.index if value_counts_app[app_type] < application_threshold]\n",
    "\n",
    "# Replace in dataframe - application type\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning classification\n",
    "classification_threshold = 800\n",
    "value_counts_class = application_df['CLASSIFICATION'].value_counts()\n",
    "classifications_to_replace = [cls for cls in value_counts_class.index if value_counts_class[cls] < classification_threshold]\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other   \n",
       "0       1     5000              1                   False  \\\n",
       "1       1   108590              1                   False   \n",
       "2       1     5000              0                   False   \n",
       "3       1     6692              1                   False   \n",
       "4       1   142590              1                   False   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3   \n",
       "0                  True                 False                False  \\\n",
       "1                 False                 False                 True   \n",
       "2                 False                 False                False   \n",
       "3                 False                 False                 True   \n",
       "4                 False                 False                 True   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...   \n",
       "0                False                False                False  ...  \\\n",
       "1                False                False                False  ...   \n",
       "2                False                 True                False  ...   \n",
       "3                False                False                False  ...   \n",
       "4                False                False                False  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999   \n",
       "0              False                   False                     False  \\\n",
       "1               True                   False                     False   \n",
       "2              False                   False                     False   \n",
       "3              False                    True                     False   \n",
       "4              False                   False                      True   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999   \n",
       "0               False             False                   False  \\\n",
       "1               False             False                   False   \n",
       "2               False             False                   False   \n",
       "3               False             False                   False   \n",
       "4               False             False                   False   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N   \n",
       "0            False              False                      True  \\\n",
       "1            False              False                      True   \n",
       "2            False              False                      True   \n",
       "3            False              False                      True   \n",
       "4            False              False                      True   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                     False  \n",
       "1                     False  \n",
       "2                     False  \n",
       "3                     False  \n",
       "4                     False  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with dummies\n",
    "application_df = pd.get_dummies(application_df, columns=['APPLICATION_TYPE', 'CLASSIFICATION', 'AFFILIATION', 'ORGANIZATION', 'USE_CASE', 'INCOME_AMT','SPECIAL_CONSIDERATIONS'])\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_optimisation_df = application_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "features = nn_optimisation_df.drop(columns=['IS_SUCCESSFUL'])\n",
    "target = nn_optimisation_df['IS_SUCCESSFUL']\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising the Model via model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading original model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "original_model = load_model(\"model/AlphabetSoupCharity.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5388 - accuracy: 0.7395 - 311ms/epoch - 1ms/step\n",
      "Loss: 0.5388383269309998, Accuracy: 0.7394751906394958\n"
     ]
    }
   ],
   "source": [
    "# Confirming model loaded properly.\n",
    "original_model_loss, original_model_accuracy = original_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {original_model_loss}, Accuracy: {original_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "original_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5432 - accuracy: 0.7346\n",
      "Epoch 2/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7363\n",
      "Epoch 3/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5416 - accuracy: 0.7360\n",
      "Epoch 4/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5406 - accuracy: 0.7359\n",
      "Epoch 5/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7365\n",
      "Epoch 6/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5409 - accuracy: 0.7359\n",
      "Epoch 7/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5403 - accuracy: 0.7368\n",
      "Epoch 8/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5402 - accuracy: 0.7370\n",
      "Epoch 9/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7365\n",
      "Epoch 10/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7362\n",
      "Epoch 11/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5401 - accuracy: 0.7359\n",
      "Epoch 12/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7368\n",
      "Epoch 13/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5398 - accuracy: 0.7367\n",
      "Epoch 14/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7367\n",
      "Epoch 15/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7366\n",
      "Epoch 16/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7365\n",
      "Epoch 17/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.7367\n",
      "Epoch 18/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7379\n",
      "Epoch 19/300\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5391 - accuracy: 0.7377\n",
      "Epoch 20/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7370\n",
      "Epoch 21/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.7371\n",
      "Epoch 22/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7375\n",
      "Epoch 23/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7372\n",
      "Epoch 24/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7366\n",
      "Epoch 25/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5393 - accuracy: 0.7367\n",
      "Epoch 26/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7369\n",
      "Epoch 27/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7379\n",
      "Epoch 28/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7374\n",
      "Epoch 29/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.7367\n",
      "Epoch 30/300\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5388 - accuracy: 0.7376\n",
      "Epoch 31/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5386 - accuracy: 0.7374\n",
      "Epoch 32/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7369\n",
      "Epoch 33/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7364\n",
      "Epoch 34/300\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5388 - accuracy: 0.7373\n",
      "Epoch 35/300\n",
      "804/804 [==============================] - 1s 999us/step - loss: 0.5386 - accuracy: 0.7371\n",
      "Epoch 36/300\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5385 - accuracy: 0.7371\n",
      "Epoch 37/300\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5387 - accuracy: 0.7370\n",
      "Epoch 38/300\n",
      "804/804 [==============================] - 1s 967us/step - loss: 0.5387 - accuracy: 0.7369\n",
      "Epoch 39/300\n",
      "804/804 [==============================] - 1s 955us/step - loss: 0.5383 - accuracy: 0.7376\n",
      "Epoch 40/300\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5382 - accuracy: 0.7369\n",
      "Epoch 41/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7362\n",
      "Epoch 42/300\n",
      "804/804 [==============================] - 1s 994us/step - loss: 0.5380 - accuracy: 0.7371\n",
      "Epoch 43/300\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5382 - accuracy: 0.7364\n",
      "Epoch 44/300\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5384 - accuracy: 0.7361\n",
      "Epoch 45/300\n",
      "804/804 [==============================] - 1s 989us/step - loss: 0.5383 - accuracy: 0.7385\n",
      "Epoch 46/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7372\n",
      "Epoch 47/300\n",
      "804/804 [==============================] - 1s 995us/step - loss: 0.5383 - accuracy: 0.7371\n",
      "Epoch 48/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7375\n",
      "Epoch 49/300\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5380 - accuracy: 0.7369\n",
      "Epoch 50/300\n",
      "804/804 [==============================] - 1s 964us/step - loss: 0.5380 - accuracy: 0.7373\n",
      "Epoch 51/300\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5381 - accuracy: 0.7376\n",
      "Epoch 52/300\n",
      "804/804 [==============================] - 1s 961us/step - loss: 0.5383 - accuracy: 0.7364\n",
      "Epoch 53/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7372\n",
      "Epoch 54/300\n",
      "804/804 [==============================] - 1s 988us/step - loss: 0.5381 - accuracy: 0.7374\n",
      "Epoch 55/300\n",
      "804/804 [==============================] - 1s 973us/step - loss: 0.5382 - accuracy: 0.7371\n",
      "Epoch 56/300\n",
      "804/804 [==============================] - 1s 940us/step - loss: 0.5380 - accuracy: 0.7377\n",
      "Epoch 57/300\n",
      "804/804 [==============================] - 1s 969us/step - loss: 0.5377 - accuracy: 0.7373\n",
      "Epoch 58/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7376\n",
      "Epoch 59/300\n",
      "804/804 [==============================] - 1s 950us/step - loss: 0.5376 - accuracy: 0.7374\n",
      "Epoch 60/300\n",
      "804/804 [==============================] - 1s 990us/step - loss: 0.5379 - accuracy: 0.7373\n",
      "Epoch 61/300\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5378 - accuracy: 0.7380\n",
      "Epoch 62/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.7372\n",
      "Epoch 63/300\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5378 - accuracy: 0.7376\n",
      "Epoch 64/300\n",
      "804/804 [==============================] - 1s 979us/step - loss: 0.5376 - accuracy: 0.7372\n",
      "Epoch 65/300\n",
      "804/804 [==============================] - 1s 972us/step - loss: 0.5379 - accuracy: 0.7371\n",
      "Epoch 66/300\n",
      "804/804 [==============================] - 1s 984us/step - loss: 0.5375 - accuracy: 0.7381\n",
      "Epoch 67/300\n",
      "804/804 [==============================] - 1s 982us/step - loss: 0.5379 - accuracy: 0.7363\n",
      "Epoch 68/300\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5375 - accuracy: 0.7384\n",
      "Epoch 69/300\n",
      "804/804 [==============================] - 1s 996us/step - loss: 0.5377 - accuracy: 0.7373\n",
      "Epoch 70/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7367\n",
      "Epoch 71/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7383\n",
      "Epoch 72/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7381\n",
      "Epoch 73/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7380\n",
      "Epoch 74/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7378\n",
      "Epoch 75/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7372\n",
      "Epoch 76/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7378\n",
      "Epoch 77/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7376\n",
      "Epoch 78/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7368\n",
      "Epoch 79/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7375\n",
      "Epoch 80/300\n",
      "804/804 [==============================] - 1s 998us/step - loss: 0.5375 - accuracy: 0.7378\n",
      "Epoch 81/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7372\n",
      "Epoch 82/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7376\n",
      "Epoch 83/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7369\n",
      "Epoch 84/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7381\n",
      "Epoch 85/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7371\n",
      "Epoch 86/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7374\n",
      "Epoch 87/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.7376\n",
      "Epoch 88/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7372\n",
      "Epoch 89/300\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5371 - accuracy: 0.7367\n",
      "Epoch 90/300\n",
      "804/804 [==============================] - 1s 997us/step - loss: 0.5372 - accuracy: 0.7368\n",
      "Epoch 91/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7376\n",
      "Epoch 92/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7381\n",
      "Epoch 93/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7374\n",
      "Epoch 94/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7370\n",
      "Epoch 95/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7377\n",
      "Epoch 96/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7377\n",
      "Epoch 97/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7379\n",
      "Epoch 98/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7372\n",
      "Epoch 99/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7382\n",
      "Epoch 100/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7383\n",
      "Epoch 101/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7371\n",
      "Epoch 102/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7382\n",
      "Epoch 103/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7369\n",
      "Epoch 104/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7385\n",
      "Epoch 105/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7380\n",
      "Epoch 106/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7375\n",
      "Epoch 107/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7377\n",
      "Epoch 108/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7378\n",
      "Epoch 109/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7374\n",
      "Epoch 110/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7369\n",
      "Epoch 111/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7376\n",
      "Epoch 112/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7381\n",
      "Epoch 113/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7379\n",
      "Epoch 114/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7375\n",
      "Epoch 115/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7377\n",
      "Epoch 116/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7378\n",
      "Epoch 117/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7378\n",
      "Epoch 118/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7386\n",
      "Epoch 119/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7374\n",
      "Epoch 120/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7379\n",
      "Epoch 121/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7376\n",
      "Epoch 122/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7376\n",
      "Epoch 123/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7384\n",
      "Epoch 124/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7380\n",
      "Epoch 125/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7378\n",
      "Epoch 126/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7380\n",
      "Epoch 127/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7373\n",
      "Epoch 128/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7384\n",
      "Epoch 129/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7390\n",
      "Epoch 130/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7373\n",
      "Epoch 131/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5367 - accuracy: 0.7384\n",
      "Epoch 132/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7385\n",
      "Epoch 133/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7376\n",
      "Epoch 134/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7390\n",
      "Epoch 135/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7383\n",
      "Epoch 136/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7375\n",
      "Epoch 137/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7386\n",
      "Epoch 138/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7379\n",
      "Epoch 139/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7380\n",
      "Epoch 140/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7385\n",
      "Epoch 141/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7374\n",
      "Epoch 142/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7370\n",
      "Epoch 143/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7378\n",
      "Epoch 144/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7371\n",
      "Epoch 145/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7378\n",
      "Epoch 146/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7373\n",
      "Epoch 147/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7381\n",
      "Epoch 148/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7380\n",
      "Epoch 149/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7376\n",
      "Epoch 150/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7381\n",
      "Epoch 151/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7381\n",
      "Epoch 152/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7373\n",
      "Epoch 153/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7385\n",
      "Epoch 154/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7375\n",
      "Epoch 155/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7379\n",
      "Epoch 156/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7382\n",
      "Epoch 157/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7374\n",
      "Epoch 158/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7375\n",
      "Epoch 159/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7378\n",
      "Epoch 160/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7383\n",
      "Epoch 161/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7370\n",
      "Epoch 162/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7362\n",
      "Epoch 163/300\n",
      "804/804 [==============================] - 1s 963us/step - loss: 0.5362 - accuracy: 0.7373\n",
      "Epoch 164/300\n",
      "804/804 [==============================] - 1s 969us/step - loss: 0.5359 - accuracy: 0.7376\n",
      "Epoch 165/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7364\n",
      "Epoch 166/300\n",
      "804/804 [==============================] - 1s 978us/step - loss: 0.5361 - accuracy: 0.7385\n",
      "Epoch 167/300\n",
      "804/804 [==============================] - 1s 953us/step - loss: 0.5362 - accuracy: 0.7379\n",
      "Epoch 168/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7380\n",
      "Epoch 169/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7380\n",
      "Epoch 170/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7379\n",
      "Epoch 171/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7376\n",
      "Epoch 172/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7385\n",
      "Epoch 173/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7386\n",
      "Epoch 174/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7377\n",
      "Epoch 175/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7390\n",
      "Epoch 176/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7381\n",
      "Epoch 177/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7376\n",
      "Epoch 178/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7384\n",
      "Epoch 179/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7389\n",
      "Epoch 180/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7379\n",
      "Epoch 181/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7373\n",
      "Epoch 182/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7393\n",
      "Epoch 183/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7386\n",
      "Epoch 184/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7375\n",
      "Epoch 185/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7383\n",
      "Epoch 186/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7372\n",
      "Epoch 187/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7380\n",
      "Epoch 188/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7376\n",
      "Epoch 189/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7385\n",
      "Epoch 190/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7376\n",
      "Epoch 191/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7377\n",
      "Epoch 192/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7387\n",
      "Epoch 193/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7373\n",
      "Epoch 194/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7379\n",
      "Epoch 195/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7381\n",
      "Epoch 196/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7382\n",
      "Epoch 197/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7377\n",
      "Epoch 198/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7389\n",
      "Epoch 199/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7381\n",
      "Epoch 200/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7377\n",
      "Epoch 201/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7372\n",
      "Epoch 202/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7378\n",
      "Epoch 203/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7387\n",
      "Epoch 204/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7386\n",
      "Epoch 205/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7378\n",
      "Epoch 206/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7366\n",
      "Epoch 207/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7385\n",
      "Epoch 208/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7373\n",
      "Epoch 209/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7375\n",
      "Epoch 210/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7377\n",
      "Epoch 211/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7379\n",
      "Epoch 212/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7382\n",
      "Epoch 213/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7360\n",
      "Epoch 214/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7380\n",
      "Epoch 215/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7386\n",
      "Epoch 216/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7383\n",
      "Epoch 217/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7375\n",
      "Epoch 218/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7383\n",
      "Epoch 219/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7388\n",
      "Epoch 220/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7371\n",
      "Epoch 221/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7383\n",
      "Epoch 222/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7383\n",
      "Epoch 223/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7365\n",
      "Epoch 224/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7382\n",
      "Epoch 225/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7389\n",
      "Epoch 226/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7380\n",
      "Epoch 227/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7376\n",
      "Epoch 228/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7378\n",
      "Epoch 229/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7383\n",
      "Epoch 230/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7384\n",
      "Epoch 231/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7379\n",
      "Epoch 232/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7380\n",
      "Epoch 233/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7379\n",
      "Epoch 234/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7390\n",
      "Epoch 235/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7388\n",
      "Epoch 236/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7384\n",
      "Epoch 237/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7379\n",
      "Epoch 238/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7385\n",
      "Epoch 239/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7376\n",
      "Epoch 240/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7387\n",
      "Epoch 241/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7389\n",
      "Epoch 242/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7376\n",
      "Epoch 243/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7376\n",
      "Epoch 244/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7394\n",
      "Epoch 245/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7392\n",
      "Epoch 246/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7385\n",
      "Epoch 247/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7390\n",
      "Epoch 248/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7379\n",
      "Epoch 249/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7376\n",
      "Epoch 250/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7383\n",
      "Epoch 251/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7382\n",
      "Epoch 252/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7386\n",
      "Epoch 253/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7376\n",
      "Epoch 254/300\n",
      "804/804 [==============================] - 1s 993us/step - loss: 0.5351 - accuracy: 0.7381\n",
      "Epoch 255/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7374\n",
      "Epoch 256/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7386\n",
      "Epoch 257/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7385\n",
      "Epoch 258/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7383\n",
      "Epoch 259/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7386\n",
      "Epoch 260/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7378\n",
      "Epoch 261/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7388\n",
      "Epoch 262/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7373\n",
      "Epoch 263/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7389\n",
      "Epoch 264/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7371\n",
      "Epoch 265/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7386\n",
      "Epoch 266/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7376\n",
      "Epoch 267/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7390\n",
      "Epoch 268/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7389\n",
      "Epoch 269/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7383\n",
      "Epoch 270/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7381\n",
      "Epoch 271/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7375\n",
      "Epoch 272/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7385\n",
      "Epoch 273/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7387\n",
      "Epoch 274/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7381\n",
      "Epoch 275/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7373\n",
      "Epoch 276/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7379\n",
      "Epoch 277/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5356 - accuracy: 0.7372\n",
      "Epoch 278/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7383\n",
      "Epoch 279/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7389\n",
      "Epoch 280/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7385\n",
      "Epoch 281/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7377\n",
      "Epoch 282/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7379\n",
      "Epoch 283/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7381\n",
      "Epoch 284/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7381\n",
      "Epoch 285/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7376\n",
      "Epoch 286/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7380\n",
      "Epoch 287/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7387\n",
      "Epoch 288/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7385\n",
      "Epoch 289/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7375\n",
      "Epoch 290/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7382\n",
      "Epoch 291/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7373\n",
      "Epoch 292/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7383\n",
      "Epoch 293/300\n",
      "804/804 [==============================] - 1s 939us/step - loss: 0.5351 - accuracy: 0.7385\n",
      "Epoch 294/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7385\n",
      "Epoch 295/300\n",
      "804/804 [==============================] - 1s 995us/step - loss: 0.5349 - accuracy: 0.7392\n",
      "Epoch 296/300\n",
      "804/804 [==============================] - 1s 985us/step - loss: 0.5349 - accuracy: 0.7385\n",
      "Epoch 297/300\n",
      "804/804 [==============================] - 1s 970us/step - loss: 0.5351 - accuracy: 0.7379\n",
      "Epoch 298/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7384\n",
      "Epoch 299/300\n",
      "804/804 [==============================] - 1s 952us/step - loss: 0.5350 - accuracy: 0.7381\n",
      "Epoch 300/300\n",
      "804/804 [==============================] - 1s 950us/step - loss: 0.5351 - accuracy: 0.7386\n"
     ]
    }
   ],
   "source": [
    "# Increase Epoch to higher amount (100 -> 300)\n",
    "fit_model = original_model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5505 - accuracy: 0.7354 - 232ms/epoch - 865us/step\n",
      "Loss: 0.5504724383354187, Accuracy: 0.7353935837745667\n"
     ]
    }
   ],
   "source": [
    "# Slightly worse performance on test set\n",
    "original_model_loss, original_model_accuracy = original_model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {original_model_loss}, Accuracy: {original_model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 43)                1892      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 22)                968       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                230       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,101\n",
      "Trainable params: 3,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Adding more hidden layers + change number of neurons\n",
    "original_model_adjusted = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "original_model_adjusted.add(tf.keras.layers.Dense(units=43, activation=\"relu\", input_dim=43))\n",
    "\n",
    "# Second hidden layer\n",
    "original_model_adjusted.add(tf.keras.layers.Dense(units=22, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "original_model_adjusted.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "original_model_adjusted.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "original_model_adjusted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile new adjusted model\n",
    "original_model_adjusted.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5766 - accuracy: 0.7177\n",
      "Epoch 2/300\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5542 - accuracy: 0.7303\n",
      "Epoch 3/300\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5513 - accuracy: 0.7318\n",
      "Epoch 4/300\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5497 - accuracy: 0.7328\n",
      "Epoch 5/300\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5481 - accuracy: 0.7328\n",
      "Epoch 6/300\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5468 - accuracy: 0.7344\n",
      "Epoch 7/300\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5464 - accuracy: 0.7345\n",
      "Epoch 8/300\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5456 - accuracy: 0.7352\n",
      "Epoch 9/300\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5454 - accuracy: 0.7349\n",
      "Epoch 10/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5448 - accuracy: 0.7352\n",
      "Epoch 11/300\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5446 - accuracy: 0.7346\n",
      "Epoch 12/300\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5441 - accuracy: 0.7352\n",
      "Epoch 13/300\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5434 - accuracy: 0.7355\n",
      "Epoch 14/300\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5437 - accuracy: 0.7360\n",
      "Epoch 15/300\n",
      "804/804 [==============================] - 1s 757us/step - loss: 0.5433 - accuracy: 0.7360\n",
      "Epoch 16/300\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5431 - accuracy: 0.7364\n",
      "Epoch 17/300\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5427 - accuracy: 0.7361\n",
      "Epoch 18/300\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5429 - accuracy: 0.7353\n",
      "Epoch 19/300\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5423 - accuracy: 0.7362\n",
      "Epoch 20/300\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5419 - accuracy: 0.7365\n",
      "Epoch 21/300\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5419 - accuracy: 0.7374\n",
      "Epoch 22/300\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5421 - accuracy: 0.7367\n",
      "Epoch 23/300\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5419 - accuracy: 0.7366\n",
      "Epoch 24/300\n",
      "804/804 [==============================] - 1s 774us/step - loss: 0.5415 - accuracy: 0.7362\n",
      "Epoch 25/300\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5415 - accuracy: 0.7369\n",
      "Epoch 26/300\n",
      "804/804 [==============================] - 1s 794us/step - loss: 0.5411 - accuracy: 0.7366\n",
      "Epoch 27/300\n",
      "804/804 [==============================] - 1s 821us/step - loss: 0.5406 - accuracy: 0.7368\n",
      "Epoch 28/300\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5406 - accuracy: 0.7377\n",
      "Epoch 29/300\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5405 - accuracy: 0.7373\n",
      "Epoch 30/300\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5408 - accuracy: 0.7368\n",
      "Epoch 31/300\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5405 - accuracy: 0.7376\n",
      "Epoch 32/300\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5402 - accuracy: 0.7381\n",
      "Epoch 33/300\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5405 - accuracy: 0.7382\n",
      "Epoch 34/300\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5402 - accuracy: 0.7378\n",
      "Epoch 35/300\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5396 - accuracy: 0.7381\n",
      "Epoch 36/300\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5401 - accuracy: 0.7387\n",
      "Epoch 37/300\n",
      "804/804 [==============================] - 1s 778us/step - loss: 0.5395 - accuracy: 0.7383\n",
      "Epoch 38/300\n",
      "804/804 [==============================] - 1s 845us/step - loss: 0.5397 - accuracy: 0.7385\n",
      "Epoch 39/300\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5396 - accuracy: 0.7385\n",
      "Epoch 40/300\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5394 - accuracy: 0.7384\n",
      "Epoch 41/300\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5388 - accuracy: 0.7383\n",
      "Epoch 42/300\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5394 - accuracy: 0.7384\n",
      "Epoch 43/300\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5390 - accuracy: 0.7379\n",
      "Epoch 44/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5392 - accuracy: 0.7386\n",
      "Epoch 45/300\n",
      "804/804 [==============================] - 1s 757us/step - loss: 0.5390 - accuracy: 0.7381\n",
      "Epoch 46/300\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5390 - accuracy: 0.7386\n",
      "Epoch 47/300\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5387 - accuracy: 0.7389\n",
      "Epoch 48/300\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5386 - accuracy: 0.7388\n",
      "Epoch 49/300\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5382 - accuracy: 0.7393\n",
      "Epoch 50/300\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5384 - accuracy: 0.7395\n",
      "Epoch 51/300\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5383 - accuracy: 0.7390\n",
      "Epoch 52/300\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5381 - accuracy: 0.7394\n",
      "Epoch 53/300\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5384 - accuracy: 0.7385\n",
      "Epoch 54/300\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5383 - accuracy: 0.7393\n",
      "Epoch 55/300\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5382 - accuracy: 0.7385\n",
      "Epoch 56/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5380 - accuracy: 0.7393\n",
      "Epoch 57/300\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5378 - accuracy: 0.7385\n",
      "Epoch 58/300\n",
      "804/804 [==============================] - 1s 765us/step - loss: 0.5377 - accuracy: 0.7395\n",
      "Epoch 59/300\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5377 - accuracy: 0.7391\n",
      "Epoch 60/300\n",
      "804/804 [==============================] - 1s 765us/step - loss: 0.5376 - accuracy: 0.7388\n",
      "Epoch 61/300\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5376 - accuracy: 0.7396\n",
      "Epoch 62/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5373 - accuracy: 0.7389\n",
      "Epoch 63/300\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5375 - accuracy: 0.7390\n",
      "Epoch 64/300\n",
      "804/804 [==============================] - 1s 826us/step - loss: 0.5372 - accuracy: 0.7384\n",
      "Epoch 65/300\n",
      "804/804 [==============================] - 1s 821us/step - loss: 0.5370 - accuracy: 0.7393\n",
      "Epoch 66/300\n",
      "804/804 [==============================] - 1s 863us/step - loss: 0.5370 - accuracy: 0.7403\n",
      "Epoch 67/300\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5371 - accuracy: 0.7390\n",
      "Epoch 68/300\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5374 - accuracy: 0.7402\n",
      "Epoch 69/300\n",
      "804/804 [==============================] - 1s 776us/step - loss: 0.5367 - accuracy: 0.7395\n",
      "Epoch 70/300\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5368 - accuracy: 0.7395\n",
      "Epoch 71/300\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5365 - accuracy: 0.7394\n",
      "Epoch 72/300\n",
      "804/804 [==============================] - 1s 813us/step - loss: 0.5368 - accuracy: 0.7400\n",
      "Epoch 73/300\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5370 - accuracy: 0.7401\n",
      "Epoch 74/300\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5367 - accuracy: 0.7400\n",
      "Epoch 75/300\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5370 - accuracy: 0.7395\n",
      "Epoch 76/300\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5367 - accuracy: 0.7392\n",
      "Epoch 77/300\n",
      "804/804 [==============================] - 1s 723us/step - loss: 0.5367 - accuracy: 0.7399\n",
      "Epoch 78/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5368 - accuracy: 0.7390\n",
      "Epoch 79/300\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5363 - accuracy: 0.7401\n",
      "Epoch 80/300\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5361 - accuracy: 0.7399\n",
      "Epoch 81/300\n",
      "804/804 [==============================] - 1s 713us/step - loss: 0.5366 - accuracy: 0.7403\n",
      "Epoch 82/300\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5363 - accuracy: 0.7397\n",
      "Epoch 83/300\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5359 - accuracy: 0.7400\n",
      "Epoch 84/300\n",
      "804/804 [==============================] - 1s 700us/step - loss: 0.5360 - accuracy: 0.7399\n",
      "Epoch 85/300\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5356 - accuracy: 0.7402\n",
      "Epoch 86/300\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5363 - accuracy: 0.7399\n",
      "Epoch 87/300\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5358 - accuracy: 0.7402\n",
      "Epoch 88/300\n",
      "804/804 [==============================] - 1s 764us/step - loss: 0.5354 - accuracy: 0.7402\n",
      "Epoch 89/300\n",
      "804/804 [==============================] - 1s 799us/step - loss: 0.5360 - accuracy: 0.7403\n",
      "Epoch 90/300\n",
      "804/804 [==============================] - 1s 782us/step - loss: 0.5358 - accuracy: 0.7404\n",
      "Epoch 91/300\n",
      "804/804 [==============================] - 1s 775us/step - loss: 0.5357 - accuracy: 0.7406\n",
      "Epoch 92/300\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5356 - accuracy: 0.7404\n",
      "Epoch 93/300\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5358 - accuracy: 0.7399\n",
      "Epoch 94/300\n",
      "804/804 [==============================] - 1s 784us/step - loss: 0.5358 - accuracy: 0.7402\n",
      "Epoch 95/300\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5357 - accuracy: 0.7399\n",
      "Epoch 96/300\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5354 - accuracy: 0.7405\n",
      "Epoch 97/300\n",
      "804/804 [==============================] - 1s 768us/step - loss: 0.5356 - accuracy: 0.7406\n",
      "Epoch 98/300\n",
      "804/804 [==============================] - 1s 838us/step - loss: 0.5352 - accuracy: 0.7402\n",
      "Epoch 99/300\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5357 - accuracy: 0.7402\n",
      "Epoch 100/300\n",
      "804/804 [==============================] - 1s 811us/step - loss: 0.5355 - accuracy: 0.7392\n",
      "Epoch 101/300\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5358 - accuracy: 0.7402\n",
      "Epoch 102/300\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5350 - accuracy: 0.7410\n",
      "Epoch 103/300\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5349 - accuracy: 0.7409\n",
      "Epoch 104/300\n",
      "804/804 [==============================] - 1s 796us/step - loss: 0.5351 - accuracy: 0.7405\n",
      "Epoch 105/300\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5353 - accuracy: 0.7405\n",
      "Epoch 106/300\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5348 - accuracy: 0.7410\n",
      "Epoch 107/300\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5351 - accuracy: 0.7406\n",
      "Epoch 108/300\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5351 - accuracy: 0.7406\n",
      "Epoch 109/300\n",
      "804/804 [==============================] - 1s 718us/step - loss: 0.5352 - accuracy: 0.7409\n",
      "Epoch 110/300\n",
      "804/804 [==============================] - 1s 709us/step - loss: 0.5348 - accuracy: 0.7407\n",
      "Epoch 111/300\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5351 - accuracy: 0.7413\n",
      "Epoch 112/300\n",
      "804/804 [==============================] - 1s 809us/step - loss: 0.5350 - accuracy: 0.7399\n",
      "Epoch 113/300\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5351 - accuracy: 0.7407\n",
      "Epoch 114/300\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5352 - accuracy: 0.7393\n",
      "Epoch 115/300\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5347 - accuracy: 0.7403\n",
      "Epoch 116/300\n",
      "804/804 [==============================] - 1s 800us/step - loss: 0.5349 - accuracy: 0.7403\n",
      "Epoch 117/300\n",
      "804/804 [==============================] - 1s 787us/step - loss: 0.5346 - accuracy: 0.7402\n",
      "Epoch 118/300\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5348 - accuracy: 0.7406\n",
      "Epoch 119/300\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5348 - accuracy: 0.7407\n",
      "Epoch 120/300\n",
      "804/804 [==============================] - 1s 777us/step - loss: 0.5349 - accuracy: 0.7399\n",
      "Epoch 121/300\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5346 - accuracy: 0.7401\n",
      "Epoch 122/300\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5345 - accuracy: 0.7403\n",
      "Epoch 123/300\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5346 - accuracy: 0.7403\n",
      "Epoch 124/300\n",
      "804/804 [==============================] - 1s 749us/step - loss: 0.5345 - accuracy: 0.7406\n",
      "Epoch 125/300\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5345 - accuracy: 0.7403\n",
      "Epoch 126/300\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5347 - accuracy: 0.7409\n",
      "Epoch 127/300\n",
      "804/804 [==============================] - 1s 739us/step - loss: 0.5343 - accuracy: 0.7403\n",
      "Epoch 128/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5344 - accuracy: 0.7412\n",
      "Epoch 129/300\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5340 - accuracy: 0.7402\n",
      "Epoch 130/300\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5345 - accuracy: 0.7399\n",
      "Epoch 131/300\n",
      "804/804 [==============================] - 1s 757us/step - loss: 0.5344 - accuracy: 0.7400\n",
      "Epoch 132/300\n",
      "804/804 [==============================] - 1s 739us/step - loss: 0.5343 - accuracy: 0.7398\n",
      "Epoch 133/300\n",
      "804/804 [==============================] - 1s 731us/step - loss: 0.5342 - accuracy: 0.7403\n",
      "Epoch 134/300\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5345 - accuracy: 0.7402\n",
      "Epoch 135/300\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5345 - accuracy: 0.7406\n",
      "Epoch 136/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5345 - accuracy: 0.7404\n",
      "Epoch 137/300\n",
      "804/804 [==============================] - 1s 727us/step - loss: 0.5344 - accuracy: 0.7407\n",
      "Epoch 138/300\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5342 - accuracy: 0.7409\n",
      "Epoch 139/300\n",
      "804/804 [==============================] - 1s 786us/step - loss: 0.5339 - accuracy: 0.7407\n",
      "Epoch 140/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5343 - accuracy: 0.7395\n",
      "Epoch 141/300\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5339 - accuracy: 0.7413\n",
      "Epoch 142/300\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5342 - accuracy: 0.7407\n",
      "Epoch 143/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5341 - accuracy: 0.7402\n",
      "Epoch 144/300\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5336 - accuracy: 0.7405\n",
      "Epoch 145/300\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5341 - accuracy: 0.7404\n",
      "Epoch 146/300\n",
      "804/804 [==============================] - 1s 733us/step - loss: 0.5337 - accuracy: 0.7410\n",
      "Epoch 147/300\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5344 - accuracy: 0.7403\n",
      "Epoch 148/300\n",
      "804/804 [==============================] - 1s 780us/step - loss: 0.5339 - accuracy: 0.7406\n",
      "Epoch 149/300\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5339 - accuracy: 0.7409\n",
      "Epoch 150/300\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5334 - accuracy: 0.7409\n",
      "Epoch 151/300\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5336 - accuracy: 0.7402\n",
      "Epoch 152/300\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5336 - accuracy: 0.7412\n",
      "Epoch 153/300\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5335 - accuracy: 0.7414\n",
      "Epoch 154/300\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5336 - accuracy: 0.7410\n",
      "Epoch 155/300\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5338 - accuracy: 0.7403\n",
      "Epoch 156/300\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5335 - accuracy: 0.7405\n",
      "Epoch 157/300\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5335 - accuracy: 0.7412\n",
      "Epoch 158/300\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5336 - accuracy: 0.7417\n",
      "Epoch 159/300\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5332 - accuracy: 0.7406\n",
      "Epoch 160/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5335 - accuracy: 0.7411\n",
      "Epoch 161/300\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5334 - accuracy: 0.7413\n",
      "Epoch 162/300\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5334 - accuracy: 0.7408\n",
      "Epoch 163/300\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5334 - accuracy: 0.7409\n",
      "Epoch 164/300\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5332 - accuracy: 0.7414\n",
      "Epoch 165/300\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5337 - accuracy: 0.7404\n",
      "Epoch 166/300\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5334 - accuracy: 0.7413\n",
      "Epoch 167/300\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5330 - accuracy: 0.7416\n",
      "Epoch 168/300\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5335 - accuracy: 0.7404\n",
      "Epoch 169/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5336 - accuracy: 0.7408\n",
      "Epoch 170/300\n",
      "804/804 [==============================] - 1s 727us/step - loss: 0.5332 - accuracy: 0.7414\n",
      "Epoch 171/300\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5331 - accuracy: 0.7409\n",
      "Epoch 172/300\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5330 - accuracy: 0.7411\n",
      "Epoch 173/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5332 - accuracy: 0.7412\n",
      "Epoch 174/300\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5334 - accuracy: 0.7415\n",
      "Epoch 175/300\n",
      "804/804 [==============================] - 1s 761us/step - loss: 0.5334 - accuracy: 0.7410\n",
      "Epoch 176/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5331 - accuracy: 0.7409\n",
      "Epoch 177/300\n",
      "804/804 [==============================] - 1s 728us/step - loss: 0.5335 - accuracy: 0.7410\n",
      "Epoch 178/300\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5335 - accuracy: 0.7412\n",
      "Epoch 179/300\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5329 - accuracy: 0.7411\n",
      "Epoch 180/300\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5329 - accuracy: 0.7416\n",
      "Epoch 181/300\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5332 - accuracy: 0.7406\n",
      "Epoch 182/300\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5329 - accuracy: 0.7410\n",
      "Epoch 183/300\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5327 - accuracy: 0.7415\n",
      "Epoch 184/300\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5328 - accuracy: 0.7410\n",
      "Epoch 185/300\n",
      "804/804 [==============================] - 1s 740us/step - loss: 0.5332 - accuracy: 0.7413\n",
      "Epoch 186/300\n",
      "804/804 [==============================] - 1s 715us/step - loss: 0.5334 - accuracy: 0.7413\n",
      "Epoch 187/300\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5330 - accuracy: 0.7414\n",
      "Epoch 188/300\n",
      "804/804 [==============================] - 1s 709us/step - loss: 0.5325 - accuracy: 0.7414\n",
      "Epoch 189/300\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5328 - accuracy: 0.7408\n",
      "Epoch 190/300\n",
      "804/804 [==============================] - 1s 710us/step - loss: 0.5329 - accuracy: 0.7414\n",
      "Epoch 191/300\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5325 - accuracy: 0.7416\n",
      "Epoch 192/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5325 - accuracy: 0.7414\n",
      "Epoch 193/300\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5329 - accuracy: 0.7414\n",
      "Epoch 194/300\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5325 - accuracy: 0.7412\n",
      "Epoch 195/300\n",
      "804/804 [==============================] - 1s 708us/step - loss: 0.5333 - accuracy: 0.7410\n",
      "Epoch 196/300\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5325 - accuracy: 0.7410\n",
      "Epoch 197/300\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5326 - accuracy: 0.7409\n",
      "Epoch 198/300\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5326 - accuracy: 0.7414\n",
      "Epoch 199/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5327 - accuracy: 0.7415\n",
      "Epoch 200/300\n",
      "804/804 [==============================] - 1s 804us/step - loss: 0.5328 - accuracy: 0.7407\n",
      "Epoch 201/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5327 - accuracy: 0.7402\n",
      "Epoch 202/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5326 - accuracy: 0.7413\n",
      "Epoch 203/300\n",
      "804/804 [==============================] - 1s 747us/step - loss: 0.5325 - accuracy: 0.7416\n",
      "Epoch 204/300\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5323 - accuracy: 0.7410\n",
      "Epoch 205/300\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5329 - accuracy: 0.7413\n",
      "Epoch 206/300\n",
      "804/804 [==============================] - 1s 760us/step - loss: 0.5324 - accuracy: 0.7415\n",
      "Epoch 207/300\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5324 - accuracy: 0.7413\n",
      "Epoch 208/300\n",
      "804/804 [==============================] - 1s 713us/step - loss: 0.5327 - accuracy: 0.7412\n",
      "Epoch 209/300\n",
      "804/804 [==============================] - 1s 708us/step - loss: 0.5327 - accuracy: 0.7404\n",
      "Epoch 210/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5323 - accuracy: 0.7414\n",
      "Epoch 211/300\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5324 - accuracy: 0.7415\n",
      "Epoch 212/300\n",
      "804/804 [==============================] - 1s 734us/step - loss: 0.5325 - accuracy: 0.7409\n",
      "Epoch 213/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5325 - accuracy: 0.7416\n",
      "Epoch 214/300\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5323 - accuracy: 0.7420\n",
      "Epoch 215/300\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5324 - accuracy: 0.7416\n",
      "Epoch 216/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5328 - accuracy: 0.7412\n",
      "Epoch 217/300\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5330 - accuracy: 0.7414\n",
      "Epoch 218/300\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5323 - accuracy: 0.7414\n",
      "Epoch 219/300\n",
      "804/804 [==============================] - 1s 773us/step - loss: 0.5324 - accuracy: 0.7417\n",
      "Epoch 220/300\n",
      "804/804 [==============================] - 1s 753us/step - loss: 0.5321 - accuracy: 0.7415\n",
      "Epoch 221/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5324 - accuracy: 0.7413\n",
      "Epoch 222/300\n",
      "804/804 [==============================] - 1s 751us/step - loss: 0.5324 - accuracy: 0.7416\n",
      "Epoch 223/300\n",
      "804/804 [==============================] - 1s 792us/step - loss: 0.5324 - accuracy: 0.7411\n",
      "Epoch 224/300\n",
      "804/804 [==============================] - 1s 716us/step - loss: 0.5324 - accuracy: 0.7414\n",
      "Epoch 225/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5324 - accuracy: 0.7416\n",
      "Epoch 226/300\n",
      "804/804 [==============================] - 1s 710us/step - loss: 0.5321 - accuracy: 0.7408\n",
      "Epoch 227/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5324 - accuracy: 0.7414\n",
      "Epoch 228/300\n",
      "804/804 [==============================] - 1s 714us/step - loss: 0.5324 - accuracy: 0.7416\n",
      "Epoch 229/300\n",
      "804/804 [==============================] - 1s 722us/step - loss: 0.5318 - accuracy: 0.7416\n",
      "Epoch 230/300\n",
      "804/804 [==============================] - 1s 735us/step - loss: 0.5321 - accuracy: 0.7418\n",
      "Epoch 231/300\n",
      "804/804 [==============================] - 1s 769us/step - loss: 0.5320 - accuracy: 0.7408\n",
      "Epoch 232/300\n",
      "804/804 [==============================] - 1s 755us/step - loss: 0.5327 - accuracy: 0.7419\n",
      "Epoch 233/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5322 - accuracy: 0.7409\n",
      "Epoch 234/300\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5320 - accuracy: 0.7415\n",
      "Epoch 235/300\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5320 - accuracy: 0.7421\n",
      "Epoch 236/300\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5326 - accuracy: 0.7412\n",
      "Epoch 237/300\n",
      "804/804 [==============================] - 1s 770us/step - loss: 0.5323 - accuracy: 0.7414\n",
      "Epoch 238/300\n",
      "804/804 [==============================] - 1s 726us/step - loss: 0.5320 - accuracy: 0.7420\n",
      "Epoch 239/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5328 - accuracy: 0.7418\n",
      "Epoch 240/300\n",
      "804/804 [==============================] - 1s 738us/step - loss: 0.5320 - accuracy: 0.7411\n",
      "Epoch 241/300\n",
      "804/804 [==============================] - 1s 772us/step - loss: 0.5314 - accuracy: 0.7421\n",
      "Epoch 242/300\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5320 - accuracy: 0.7414\n",
      "Epoch 243/300\n",
      "804/804 [==============================] - 1s 819us/step - loss: 0.5319 - accuracy: 0.7418\n",
      "Epoch 244/300\n",
      "804/804 [==============================] - 1s 785us/step - loss: 0.5321 - accuracy: 0.7416\n",
      "Epoch 245/300\n",
      "804/804 [==============================] - 1s 743us/step - loss: 0.5320 - accuracy: 0.7422\n",
      "Epoch 246/300\n",
      "804/804 [==============================] - 1s 778us/step - loss: 0.5327 - accuracy: 0.7411\n",
      "Epoch 247/300\n",
      "804/804 [==============================] - 1s 795us/step - loss: 0.5320 - accuracy: 0.7420\n",
      "Epoch 248/300\n",
      "804/804 [==============================] - 1s 725us/step - loss: 0.5318 - accuracy: 0.7405\n",
      "Epoch 249/300\n",
      "804/804 [==============================] - 1s 771us/step - loss: 0.5321 - accuracy: 0.7423\n",
      "Epoch 250/300\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5318 - accuracy: 0.7416\n",
      "Epoch 251/300\n",
      "804/804 [==============================] - 1s 710us/step - loss: 0.5319 - accuracy: 0.7416\n",
      "Epoch 252/300\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5318 - accuracy: 0.7421\n",
      "Epoch 253/300\n",
      "804/804 [==============================] - 1s 766us/step - loss: 0.5323 - accuracy: 0.7417\n",
      "Epoch 254/300\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5321 - accuracy: 0.7413\n",
      "Epoch 255/300\n",
      "804/804 [==============================] - 1s 788us/step - loss: 0.5323 - accuracy: 0.7417\n",
      "Epoch 256/300\n",
      "804/804 [==============================] - 1s 765us/step - loss: 0.5317 - accuracy: 0.7416\n",
      "Epoch 257/300\n",
      "804/804 [==============================] - 1s 767us/step - loss: 0.5316 - accuracy: 0.7414\n",
      "Epoch 258/300\n",
      "804/804 [==============================] - 1s 779us/step - loss: 0.5316 - accuracy: 0.7418\n",
      "Epoch 259/300\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5325 - accuracy: 0.7416\n",
      "Epoch 260/300\n",
      "804/804 [==============================] - 1s 756us/step - loss: 0.5319 - accuracy: 0.7416\n",
      "Epoch 261/300\n",
      "804/804 [==============================] - 1s 789us/step - loss: 0.5316 - accuracy: 0.7420\n",
      "Epoch 262/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5319 - accuracy: 0.7414\n",
      "Epoch 263/300\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5318 - accuracy: 0.7418\n",
      "Epoch 264/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5316 - accuracy: 0.7416\n",
      "Epoch 265/300\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5317 - accuracy: 0.7418\n",
      "Epoch 266/300\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5320 - accuracy: 0.7416\n",
      "Epoch 267/300\n",
      "804/804 [==============================] - 1s 736us/step - loss: 0.5318 - accuracy: 0.7418\n",
      "Epoch 268/300\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5316 - accuracy: 0.7423\n",
      "Epoch 269/300\n",
      "804/804 [==============================] - 1s 730us/step - loss: 0.5316 - accuracy: 0.7418\n",
      "Epoch 270/300\n",
      "804/804 [==============================] - 1s 732us/step - loss: 0.5315 - accuracy: 0.7415\n",
      "Epoch 271/300\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5317 - accuracy: 0.7416\n",
      "Epoch 272/300\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5314 - accuracy: 0.7412\n",
      "Epoch 273/300\n",
      "804/804 [==============================] - 1s 742us/step - loss: 0.5314 - accuracy: 0.7419\n",
      "Epoch 274/300\n",
      "804/804 [==============================] - 1s 712us/step - loss: 0.5316 - accuracy: 0.7416\n",
      "Epoch 275/300\n",
      "804/804 [==============================] - 1s 720us/step - loss: 0.5313 - accuracy: 0.7416\n",
      "Epoch 276/300\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5315 - accuracy: 0.7421\n",
      "Epoch 277/300\n",
      "804/804 [==============================] - 1s 750us/step - loss: 0.5315 - accuracy: 0.7414\n",
      "Epoch 278/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5317 - accuracy: 0.7419\n",
      "Epoch 279/300\n",
      "804/804 [==============================] - 1s 745us/step - loss: 0.5319 - accuracy: 0.7421\n",
      "Epoch 280/300\n",
      "804/804 [==============================] - 1s 790us/step - loss: 0.5314 - accuracy: 0.7414\n",
      "Epoch 281/300\n",
      "804/804 [==============================] - 1s 769us/step - loss: 0.5316 - accuracy: 0.7418\n",
      "Epoch 282/300\n",
      "804/804 [==============================] - 1s 798us/step - loss: 0.5311 - accuracy: 0.7420\n",
      "Epoch 283/300\n",
      "804/804 [==============================] - 1s 744us/step - loss: 0.5312 - accuracy: 0.7413\n",
      "Epoch 284/300\n",
      "804/804 [==============================] - 1s 746us/step - loss: 0.5314 - accuracy: 0.7418\n",
      "Epoch 285/300\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5317 - accuracy: 0.7408\n",
      "Epoch 286/300\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5314 - accuracy: 0.7421\n",
      "Epoch 287/300\n",
      "804/804 [==============================] - 1s 724us/step - loss: 0.5315 - accuracy: 0.7417\n",
      "Epoch 288/300\n",
      "804/804 [==============================] - 1s 721us/step - loss: 0.5312 - accuracy: 0.7421\n",
      "Epoch 289/300\n",
      "804/804 [==============================] - 1s 737us/step - loss: 0.5314 - accuracy: 0.7421\n",
      "Epoch 290/300\n",
      "804/804 [==============================] - 1s 754us/step - loss: 0.5315 - accuracy: 0.7419\n",
      "Epoch 291/300\n",
      "804/804 [==============================] - 1s 719us/step - loss: 0.5311 - accuracy: 0.7418\n",
      "Epoch 292/300\n",
      "804/804 [==============================] - 1s 729us/step - loss: 0.5312 - accuracy: 0.7411\n",
      "Epoch 293/300\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5314 - accuracy: 0.7412\n",
      "Epoch 294/300\n",
      "804/804 [==============================] - 1s 758us/step - loss: 0.5314 - accuracy: 0.7421\n",
      "Epoch 295/300\n",
      "804/804 [==============================] - 1s 759us/step - loss: 0.5314 - accuracy: 0.7418\n",
      "Epoch 296/300\n",
      "804/804 [==============================] - 1s 741us/step - loss: 0.5312 - accuracy: 0.7418\n",
      "Epoch 297/300\n",
      "804/804 [==============================] - 1s 717us/step - loss: 0.5312 - accuracy: 0.7423\n",
      "Epoch 298/300\n",
      "804/804 [==============================] - 1s 709us/step - loss: 0.5313 - accuracy: 0.7421\n",
      "Epoch 299/300\n",
      "804/804 [==============================] - 1s 711us/step - loss: 0.5313 - accuracy: 0.7421\n",
      "Epoch 300/300\n",
      "804/804 [==============================] - 1s 748us/step - loss: 0.5313 - accuracy: 0.7422\n"
     ]
    }
   ],
   "source": [
    "fit_model_adjusted = original_model_adjusted.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5393 - accuracy: 0.7402 - 227ms/epoch - 847us/step\n",
      "Loss: 0.5392518043518066, Accuracy: 0.7401749491691589\n"
     ]
    }
   ],
   "source": [
    "# Slight accuracy increase\n",
    "model_loss, model_accuracy = original_model_adjusted.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt to change input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating copy of dataframe just in case\n",
    "nn_optimisation_df = application_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0x1e86bbda310>,\n",
       "  <matplotlib.lines.Line2D at 0x1e86bbda5b0>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0x1e86bbda850>,\n",
       "  <matplotlib.lines.Line2D at 0x1e86bbdaaf0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0x1e86bbda070>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0x1e86bbdad90>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0x1e86bbe80a0>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting distribution of ASK_AMT column\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.boxplot(nn_optimisation_df['ASK_AMT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    3.429900e+04\n",
       "mean     2.769199e+06\n",
       "std      8.713045e+07\n",
       "min      5.000000e+03\n",
       "25%      5.000000e+03\n",
       "50%      5.000000e+03\n",
       "75%      7.742000e+03\n",
       "max      8.597806e+09\n",
       "Name: ASK_AMT, dtype: float64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can see that the median is very low (5000), with max numbers in the billion.\n",
    "nn_optimisation_df['ASK_AMT'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe for less than one million ask amount\n",
    "askamt_restriction_df = nn_optimisation_df.loc[nn_optimisation_df['ASK_AMT'] < 1_000_000]\n",
    "askamt_restriction_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split and scale data on new restricted dataframe\n",
    "features = askamt_restriction_df.drop(columns=['IS_SUCCESSFUL'])\n",
    "target = askamt_restriction_df['IS_SUCCESSFUL']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target)\n",
    "\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 43)                1892      \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 22)                968       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                230       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,101\n",
      "Trainable params: 3,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# New adjusted model\n",
    "nn_model_adjusted = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn_model_adjusted.add(tf.keras.layers.Dense(units=43, activation=\"relu\", input_dim=43))\n",
    "\n",
    "# Second hidden layer\n",
    "nn_model_adjusted.add(tf.keras.layers.Dense(units=22, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn_model_adjusted.add(tf.keras.layers.Dense(units=10, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn_model_adjusted.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn_model_adjusted.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile new model\n",
    "nn_model_adjusted.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "804/804 [==============================] - 2s 1ms/step - loss: 0.5741 - accuracy: 0.7177\n",
      "Epoch 2/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5558 - accuracy: 0.7273\n",
      "Epoch 3/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5525 - accuracy: 0.7295\n",
      "Epoch 4/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5509 - accuracy: 0.7301\n",
      "Epoch 5/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5505 - accuracy: 0.7290\n",
      "Epoch 6/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5491 - accuracy: 0.7304\n",
      "Epoch 7/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5486 - accuracy: 0.7310\n",
      "Epoch 8/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5481 - accuracy: 0.7317\n",
      "Epoch 9/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5475 - accuracy: 0.7318\n",
      "Epoch 10/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5467 - accuracy: 0.7320\n",
      "Epoch 11/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5466 - accuracy: 0.7322\n",
      "Epoch 12/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5465 - accuracy: 0.7330\n",
      "Epoch 13/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5461 - accuracy: 0.7325\n",
      "Epoch 14/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5455 - accuracy: 0.7337\n",
      "Epoch 15/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5451 - accuracy: 0.7327\n",
      "Epoch 16/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5450 - accuracy: 0.7344\n",
      "Epoch 17/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5449 - accuracy: 0.7346\n",
      "Epoch 18/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5443 - accuracy: 0.7345\n",
      "Epoch 19/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5442 - accuracy: 0.7334\n",
      "Epoch 20/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5445 - accuracy: 0.7336\n",
      "Epoch 21/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5438 - accuracy: 0.7350\n",
      "Epoch 22/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7360\n",
      "Epoch 23/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5435 - accuracy: 0.7342\n",
      "Epoch 24/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5430 - accuracy: 0.7339\n",
      "Epoch 25/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7343\n",
      "Epoch 26/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5429 - accuracy: 0.7353\n",
      "Epoch 27/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7356\n",
      "Epoch 28/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7355\n",
      "Epoch 29/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5431 - accuracy: 0.7350\n",
      "Epoch 30/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7353\n",
      "Epoch 31/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5427 - accuracy: 0.7360\n",
      "Epoch 32/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5423 - accuracy: 0.7343\n",
      "Epoch 33/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5421 - accuracy: 0.7350\n",
      "Epoch 34/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5420 - accuracy: 0.7362\n",
      "Epoch 35/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5417 - accuracy: 0.7356\n",
      "Epoch 36/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5418 - accuracy: 0.7352\n",
      "Epoch 37/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5414 - accuracy: 0.7356\n",
      "Epoch 38/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7360\n",
      "Epoch 39/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5411 - accuracy: 0.7366\n",
      "Epoch 40/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5413 - accuracy: 0.7353\n",
      "Epoch 41/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7373\n",
      "Epoch 42/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5410 - accuracy: 0.7351\n",
      "Epoch 43/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5408 - accuracy: 0.7355\n",
      "Epoch 44/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5407 - accuracy: 0.7366\n",
      "Epoch 45/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5405 - accuracy: 0.7357\n",
      "Epoch 46/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7362\n",
      "Epoch 47/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7363\n",
      "Epoch 48/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5399 - accuracy: 0.7365\n",
      "Epoch 49/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7359\n",
      "Epoch 50/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5404 - accuracy: 0.7367\n",
      "Epoch 51/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7360\n",
      "Epoch 52/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7367\n",
      "Epoch 53/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5396 - accuracy: 0.7363\n",
      "Epoch 54/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5400 - accuracy: 0.7364\n",
      "Epoch 55/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5395 - accuracy: 0.7377\n",
      "Epoch 56/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5394 - accuracy: 0.7364\n",
      "Epoch 57/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5397 - accuracy: 0.7369\n",
      "Epoch 58/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5391 - accuracy: 0.7374\n",
      "Epoch 59/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5390 - accuracy: 0.7373\n",
      "Epoch 60/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5386 - accuracy: 0.7371\n",
      "Epoch 61/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5386 - accuracy: 0.7376\n",
      "Epoch 62/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5392 - accuracy: 0.7369\n",
      "Epoch 63/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5389 - accuracy: 0.7371\n",
      "Epoch 64/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5388 - accuracy: 0.7378\n",
      "Epoch 65/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7376\n",
      "Epoch 66/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5386 - accuracy: 0.7375\n",
      "Epoch 67/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7375\n",
      "Epoch 68/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7386\n",
      "Epoch 69/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7375\n",
      "Epoch 70/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5385 - accuracy: 0.7370\n",
      "Epoch 71/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7378\n",
      "Epoch 72/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5387 - accuracy: 0.7375\n",
      "Epoch 73/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7378\n",
      "Epoch 74/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7379\n",
      "Epoch 75/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7380\n",
      "Epoch 76/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5384 - accuracy: 0.7384\n",
      "Epoch 77/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7372\n",
      "Epoch 78/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7372\n",
      "Epoch 79/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5379 - accuracy: 0.7386\n",
      "Epoch 80/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5380 - accuracy: 0.7379\n",
      "Epoch 81/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5382 - accuracy: 0.7380\n",
      "Epoch 82/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7388\n",
      "Epoch 83/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5377 - accuracy: 0.7382\n",
      "Epoch 84/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5381 - accuracy: 0.7387\n",
      "Epoch 85/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7384\n",
      "Epoch 86/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5378 - accuracy: 0.7381\n",
      "Epoch 87/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5375 - accuracy: 0.7380\n",
      "Epoch 88/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7381\n",
      "Epoch 89/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7390\n",
      "Epoch 90/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7383\n",
      "Epoch 91/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5374 - accuracy: 0.7385\n",
      "Epoch 92/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5376 - accuracy: 0.7384\n",
      "Epoch 93/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7385\n",
      "Epoch 94/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5373 - accuracy: 0.7385\n",
      "Epoch 95/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7381\n",
      "Epoch 96/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7390\n",
      "Epoch 97/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5371 - accuracy: 0.7383\n",
      "Epoch 98/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7393\n",
      "Epoch 99/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7383\n",
      "Epoch 100/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7388\n",
      "Epoch 101/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7390\n",
      "Epoch 102/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7391\n",
      "Epoch 103/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7389\n",
      "Epoch 104/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5365 - accuracy: 0.7390\n",
      "Epoch 105/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7390\n",
      "Epoch 106/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5370 - accuracy: 0.7386\n",
      "Epoch 107/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5368 - accuracy: 0.7382\n",
      "Epoch 108/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5366 - accuracy: 0.7394\n",
      "Epoch 109/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7388\n",
      "Epoch 110/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5369 - accuracy: 0.7390\n",
      "Epoch 111/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5372 - accuracy: 0.7393\n",
      "Epoch 112/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7399\n",
      "Epoch 113/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7384\n",
      "Epoch 114/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7390\n",
      "Epoch 115/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7390\n",
      "Epoch 116/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7395\n",
      "Epoch 117/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7387\n",
      "Epoch 118/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5360 - accuracy: 0.7391\n",
      "Epoch 119/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7392\n",
      "Epoch 120/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7391\n",
      "Epoch 121/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7389\n",
      "Epoch 122/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7394\n",
      "Epoch 123/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7392\n",
      "Epoch 124/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7390\n",
      "Epoch 125/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5359 - accuracy: 0.7391\n",
      "Epoch 126/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5364 - accuracy: 0.7390\n",
      "Epoch 127/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7396\n",
      "Epoch 128/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5361 - accuracy: 0.7393\n",
      "Epoch 129/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5362 - accuracy: 0.7397\n",
      "Epoch 130/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7389\n",
      "Epoch 131/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7386\n",
      "Epoch 132/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7386\n",
      "Epoch 133/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7386\n",
      "Epoch 134/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7390\n",
      "Epoch 135/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5363 - accuracy: 0.7390\n",
      "Epoch 136/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7388\n",
      "Epoch 137/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7397\n",
      "Epoch 138/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7396\n",
      "Epoch 139/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7386\n",
      "Epoch 140/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7393\n",
      "Epoch 141/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5358 - accuracy: 0.7399\n",
      "Epoch 142/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7393\n",
      "Epoch 143/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7387\n",
      "Epoch 144/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7394\n",
      "Epoch 145/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5355 - accuracy: 0.7396\n",
      "Epoch 146/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5357 - accuracy: 0.7397\n",
      "Epoch 147/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7395\n",
      "Epoch 148/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7390\n",
      "Epoch 149/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7390\n",
      "Epoch 150/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7399\n",
      "Epoch 151/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7393\n",
      "Epoch 152/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5352 - accuracy: 0.7398\n",
      "Epoch 153/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7400\n",
      "Epoch 154/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7397\n",
      "Epoch 155/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7399\n",
      "Epoch 156/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7404\n",
      "Epoch 157/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5351 - accuracy: 0.7387\n",
      "Epoch 158/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7397\n",
      "Epoch 159/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7397\n",
      "Epoch 160/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5354 - accuracy: 0.7401\n",
      "Epoch 161/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7393\n",
      "Epoch 162/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7396\n",
      "Epoch 163/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7399\n",
      "Epoch 164/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7397\n",
      "Epoch 165/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.7400\n",
      "Epoch 166/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7402\n",
      "Epoch 167/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5353 - accuracy: 0.7400\n",
      "Epoch 168/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7398\n",
      "Epoch 169/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7392\n",
      "Epoch 170/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7394\n",
      "Epoch 171/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7391\n",
      "Epoch 172/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5348 - accuracy: 0.7395\n",
      "Epoch 173/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.7400\n",
      "Epoch 174/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7395\n",
      "Epoch 175/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7399\n",
      "Epoch 176/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5350 - accuracy: 0.7397\n",
      "Epoch 177/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5349 - accuracy: 0.7400\n",
      "Epoch 178/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7399\n",
      "Epoch 179/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7393\n",
      "Epoch 180/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7398\n",
      "Epoch 181/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.7405\n",
      "Epoch 182/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7395\n",
      "Epoch 183/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7394\n",
      "Epoch 184/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7402\n",
      "Epoch 185/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7397\n",
      "Epoch 186/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.7396\n",
      "Epoch 187/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7397\n",
      "Epoch 188/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5347 - accuracy: 0.7395\n",
      "Epoch 189/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7390\n",
      "Epoch 190/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5346 - accuracy: 0.7393\n",
      "Epoch 191/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7400\n",
      "Epoch 192/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7400\n",
      "Epoch 193/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7388\n",
      "Epoch 194/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7404\n",
      "Epoch 195/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7403\n",
      "Epoch 196/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7395\n",
      "Epoch 197/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7395\n",
      "Epoch 198/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7394\n",
      "Epoch 199/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7402\n",
      "Epoch 200/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7394\n",
      "Epoch 201/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.7395\n",
      "Epoch 202/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5344 - accuracy: 0.7404\n",
      "Epoch 203/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7399\n",
      "Epoch 204/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7389\n",
      "Epoch 205/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5345 - accuracy: 0.7397\n",
      "Epoch 206/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7399\n",
      "Epoch 207/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7401\n",
      "Epoch 208/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7395\n",
      "Epoch 209/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7402\n",
      "Epoch 210/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7390\n",
      "Epoch 211/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7400\n",
      "Epoch 212/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7396\n",
      "Epoch 213/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7397\n",
      "Epoch 214/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7393\n",
      "Epoch 215/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7395\n",
      "Epoch 216/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7403\n",
      "Epoch 217/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7404\n",
      "Epoch 218/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7402\n",
      "Epoch 219/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7399\n",
      "Epoch 220/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.7395\n",
      "Epoch 221/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7397\n",
      "Epoch 222/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7406\n",
      "Epoch 223/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5341 - accuracy: 0.7406\n",
      "Epoch 224/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7403\n",
      "Epoch 225/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7396\n",
      "Epoch 226/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5343 - accuracy: 0.7399\n",
      "Epoch 227/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7401\n",
      "Epoch 228/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7402\n",
      "Epoch 229/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7398\n",
      "Epoch 230/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7401\n",
      "Epoch 231/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5342 - accuracy: 0.7399\n",
      "Epoch 232/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7400\n",
      "Epoch 233/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7407\n",
      "Epoch 234/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.7399\n",
      "Epoch 235/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7397\n",
      "Epoch 236/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7402\n",
      "Epoch 237/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7403\n",
      "Epoch 238/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7401\n",
      "Epoch 239/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7401\n",
      "Epoch 240/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7404\n",
      "Epoch 241/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5337 - accuracy: 0.7396\n",
      "Epoch 242/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7403\n",
      "Epoch 243/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7400\n",
      "Epoch 244/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7397\n",
      "Epoch 245/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7399\n",
      "Epoch 246/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7397\n",
      "Epoch 247/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7404\n",
      "Epoch 248/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5339 - accuracy: 0.7393\n",
      "Epoch 249/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7400\n",
      "Epoch 250/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.7395\n",
      "Epoch 251/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7402\n",
      "Epoch 252/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7401\n",
      "Epoch 253/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7404\n",
      "Epoch 254/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5340 - accuracy: 0.7391\n",
      "Epoch 255/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7404\n",
      "Epoch 256/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7392\n",
      "Epoch 257/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7401\n",
      "Epoch 258/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7404\n",
      "Epoch 259/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7403\n",
      "Epoch 260/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5329 - accuracy: 0.7400\n",
      "Epoch 261/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7406\n",
      "Epoch 262/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7395\n",
      "Epoch 263/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7395\n",
      "Epoch 264/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7397\n",
      "Epoch 265/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7405\n",
      "Epoch 266/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7397\n",
      "Epoch 267/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7401\n",
      "Epoch 268/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7401\n",
      "Epoch 269/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5329 - accuracy: 0.7410\n",
      "Epoch 270/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7402\n",
      "Epoch 271/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7396\n",
      "Epoch 272/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7409\n",
      "Epoch 273/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7397\n",
      "Epoch 274/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7407\n",
      "Epoch 275/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7393\n",
      "Epoch 276/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5330 - accuracy: 0.7399\n",
      "Epoch 277/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5330 - accuracy: 0.7411\n",
      "Epoch 278/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7398\n",
      "Epoch 279/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7406\n",
      "Epoch 280/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7400\n",
      "Epoch 281/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7405\n",
      "Epoch 282/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5335 - accuracy: 0.7397\n",
      "Epoch 283/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.7399\n",
      "Epoch 284/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5338 - accuracy: 0.7406\n",
      "Epoch 285/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7397\n",
      "Epoch 286/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5330 - accuracy: 0.7400\n",
      "Epoch 287/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5327 - accuracy: 0.7406\n",
      "Epoch 288/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5336 - accuracy: 0.7400\n",
      "Epoch 289/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5334 - accuracy: 0.7405\n",
      "Epoch 290/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5333 - accuracy: 0.7406\n",
      "Epoch 291/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5329 - accuracy: 0.7399\n",
      "Epoch 292/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7402\n",
      "Epoch 293/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5331 - accuracy: 0.7399\n",
      "Epoch 294/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5328 - accuracy: 0.7402\n",
      "Epoch 295/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5330 - accuracy: 0.7410\n",
      "Epoch 296/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5329 - accuracy: 0.7405\n",
      "Epoch 297/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5330 - accuracy: 0.7402\n",
      "Epoch 298/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5330 - accuracy: 0.7398\n",
      "Epoch 299/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5332 - accuracy: 0.7400\n",
      "Epoch 300/300\n",
      "804/804 [==============================] - 1s 1ms/step - loss: 0.5329 - accuracy: 0.7407\n"
     ]
    }
   ],
   "source": [
    "# Fitting on training data\n",
    "fit_model_adjusted = nn_model_adjusted.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5613 - accuracy: 0.7333 - 305ms/epoch - 1ms/step\n",
      "Loss: 0.5612531900405884, Accuracy: 0.7332944869995117\n"
     ]
    }
   ],
   "source": [
    "# No accuracy increase detected doing this\n",
    "model_loss, model_accuracy = nn_model_adjusted.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "nn_model_adjusted.save(\"model/AlphabetSoupCharityAdjusted.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
